{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPDRjL8krPVyZtfTQ8EA3hF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saralstalin/ResponseWithQueriedData/blob/main/Chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#install necessary packages\n",
        "!pip install -q  openai mysql-connector gradio"
      ],
      "metadata": {
        "id": "ka9GufQb9o41"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import needed modules\n",
        "from google.colab import userdata\n",
        "from openai import OpenAI\n",
        "import gradio as gr\n",
        "import mysql.connector\n",
        "\n",
        "#create an instance of openai API client\n",
        "OpenAIAPIKey = userdata.get('OpenAIAPIKey')\n",
        "from openai import OpenAI\n",
        "client = OpenAI(\n",
        "    api_key=OpenAIAPIKey,\n",
        ")\n",
        "\n",
        "# call openAI API and get response message\n",
        "def GetChatCompletion(sytemPrompt, userPrompt, model=\"gpt-4o-mini\"):\n",
        "  completions = client.chat.completions.create(\n",
        "      messages=[\n",
        "          {\n",
        "              \"role\": \"user\",\n",
        "              \"content\": userPrompt,\n",
        "          }\n",
        "          ,\n",
        "          {\n",
        "              \"role\": \"system\",\n",
        "              \"content\": sytemPrompt,\n",
        "          }\n",
        "      ],\n",
        "      model=\"gpt-4o-mini\",\n",
        "  )\n",
        "  return completions.choices[0].message.content\n",
        "\n",
        "# get database connection details from Secrets\n",
        "myDBHost = userdata.get('host')\n",
        "myDBUser = userdata.get('user')\n",
        "myDBPassword = userdata.get('password')\n",
        "myDBDatabase = userdata.get('database')\n",
        "\n",
        "# create an instance of the database connection\n",
        "myDatabaseConnection = mysql.connector.connect(\n",
        "  host= myDBHost,\n",
        "  user= myDBUser,\n",
        "  password=myDBPassword,\n",
        "  database=myDBDatabase\n",
        ")\n",
        "\n",
        "# execute database queries\n",
        "def ExecuteQuery(query):\n",
        "  result = []\n",
        "  cursor = None\n",
        "  try:\n",
        "      cursor = myDatabaseConnection.cursor()\n",
        "      cursor.execute(query)\n",
        "      result = cursor.fetchall()\n",
        "  except Exception as e:\n",
        "      result = []\n",
        "  finally:\n",
        "      # Ensure the cursor is closed, even if an exception occurs\n",
        "      if cursor:\n",
        "          cursor.close()\n",
        "      return result\n",
        "\n",
        "# execute database queries\n",
        "def ExecuteQuery(query):\n",
        "  cursor = myDatabaseConnection.cursor()\n",
        "  cursor.execute(query)\n",
        "  result = cursor.fetchall()\n",
        "  return result\n",
        "\n",
        "# get list of all tables from database\n",
        "def GetTables():\n",
        "  return ExecuteQuery(\"SHOW TABLES\")\n",
        "\n",
        "# get relevant list of tables using LLM\n",
        "def GetRelevantTables(listOfTables, userPrompt):\n",
        "  systemPrompt = f\"get relevant tables from the list of tables {listOfTables} that would contain data for the user prompt. Do not explain. Make it comma separated list.\"\n",
        "  return GetChatCompletion(systemPrompt, userPrompt)\n",
        "\n",
        "# get schema of relevant tables\n",
        "def GetSchemaofRelevantTables(relevantTables):\n",
        "  relevantTableList = relevantTables.split(',')\n",
        "  schema = \"\"\n",
        "  for table in relevantTableList:\n",
        "    result = ExecuteQuery(f\"SHOW CREATE TABLE {table}\")\n",
        "    if len(result) > 0:\n",
        "      schema += result[0][1].replace('`', '') + \"\\n\\n\"\n",
        "  return schema\n",
        "\n",
        "# generate sql query using LLM\n",
        "def GenerateSQLQuery(relevantTableSchema, userPrompt):\n",
        "  systemPrompt = f\"Generate an SQL Query using the schema of the tables {relevantTableSchema} for the user prompt. Do not explain. Do not invent new tables. Do not create code tags.\"\n",
        "  return GetChatCompletion(systemPrompt, userPrompt)\n",
        "\n",
        "# format response using LLM\n",
        "def FormatResponse(queryResults, userPrompt):\n",
        "  systemPrompt = f\"Format a response using the data {queryResults} to the user prompt. Do not invent information, respond only when you are sure otherwise\";\n",
        "  return GetChatCompletion(systemPrompt, userPrompt)\n",
        "\n",
        "# run steps to generate chat response\n",
        "def Chatbot(userPrompt):\n",
        "  listOfTables = GetTables()\n",
        "  print(listOfTables)\n",
        "  relevantTables = GetRelevantTables(listOfTables, userPrompt)\n",
        "  relevantTableSchema = GetSchemaofRelevantTables(relevantTables)\n",
        "  query = GenerateSQLQuery(relevantTableSchema, userPrompt)\n",
        "  queryResults = ExecuteQuery(query)\n",
        "  response = FormatResponse(queryResults, userPrompt)\n",
        "  return response\n",
        "\n",
        "#gradio interface\n",
        "gradioInterface = gr.Interface(\n",
        "    fn=Chatbot,\n",
        "    inputs= gr.Textbox(label=\"Question\"),\n",
        "    outputs=\"text\",\n",
        "    title=\"Chatbot\")\n",
        "\n",
        "# Caution share =True will make the interface publicly available\n",
        "gradioInterface.launch(share=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "_scXUfLDXkst",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        },
        "outputId": "3af91e06-c15d-4fa4-b509-6f6f2bfb55b3"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://e3f7debbeb8eb0522f.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://e3f7debbeb8eb0522f.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    }
  ]
}
